# -*- coding: utf-8 -*-
"""
PDFì—ì„œ ì£¼ì„(Polygon / Highlight / Square) ë§ˆí¬ì—… ì˜ì—­ì€ ì œì™¸í•˜ê³ ,
ë‚˜ë¨¸ì§€ ì˜ì—­ì˜ í…ìŠ¤íŠ¸ spanì„ ìˆ˜ì§‘í•œ ë’¤

- ë¼ì¸ë²ˆí˜¸ ë‘ ì¤„ ë³‘í•©
- ì½”ë“œ + ìˆ«ì ì¡°í•©(composed tag) ìƒì„±
- dummy íƒœê·¸ í•„í„°ë§
- YOLOë¡œ instrument â†’ special_item ì¬ë¶„ë¥˜(ì„ íƒ)

ê¹Œì§€ ìˆ˜í–‰í•œ í›„

1) ê¸°ì¡´ colored_tags / composed_tags (ë””ë²„ê¹…ìš©)
2) ìµœì¢… ê²°ê³¼: page, text, type, x0, y0, x1, y1 ë§Œ ê°€ì§„ final_tags.xlsx

ë¥¼ ì €ì¥í•˜ëŠ” íŒŒì´í”„ë¼ì¸.
"""
from __future__ import annotations
import csv
from pathlib import Path
from dataclasses import dataclass
from typing import List, Tuple, Dict, Optional

import time
import re
import io

import pandas as pd
import pymupdf as fitz
from shapely.geometry import Point, Polygon
from loguru import logger
from PIL import Image
import re  # íŒŒì¼ ìµœìƒë‹¨ì— ì´ë¯¸ ìˆìœ¼ë©´ ìƒëµ


# ============== YOLO ëª¨ë¸ ì„í¬íŠ¸ (ì„ íƒ) ==============
try:
    from ultralytics import YOLO

    YOLO_AVAILABLE = True
except ImportError:
    YOLO_AVAILABLE = False
    logger.warning("ultralytics ë¯¸ì„¤ì¹˜ - YOLO ë¶„ë¥˜ ë¹„í™œì„±í™”")

# ============== ê²½ë¡œ ==============
DATA_PDF_DIR = Path("data/pdf")
OUT_DIR = Path("out")
OUT_DIR.mkdir(parents=True, exist_ok=True)

# ============== YOLO ëª¨ë¸ ê²½ë¡œ/íŒŒë¼ë¯¸í„° ==============
YOLO_MODEL_PATH = Path("runs/detect/symbol_detector/weights/best.pt")
CROP_MARGIN = 10
YOLO_CONFIDENCE = 0.25

CROP_IMG_DIR = Path("out/cropped_images")
CROP_IMG_DIR.mkdir(parents=True, exist_ok=True)
SAVE_CROPPED_IMAGES = True

# ============== ì—‘ì…€ ìƒ‰ìƒ ìŠ¤ì™€ì¹˜ (ê¸°ì¡´ ë¡œì§ ìœ ì§€) ==============
from openpyxl import load_workbook
from openpyxl.styles import PatternFill


def hex_to_argb(hex_code: str) -> str:
    if not hex_code:
        return "FFFFFFFF"
    s = hex_code.strip()
    if s.startswith("#"):
        s = s[1:]
    if len(s) != 6:
        return "FFFFFFFF"
    return "FF" + s.upper()


def make_safe_tag_for_filename(tag: str) -> str:
    """
    ìœˆë„ìš° íŒŒì¼ëª…ì— ì“¸ ìˆ˜ ìˆë„ë¡ íƒœê·¸ ë¬¸ìì—´ ì„¸íƒ
    - ê¸ˆì§€ë¬¸ì: \ / : * ? " < > |  â†’ '_'ë¡œ ì¹˜í™˜
    - ê·¸ ì™¸ í•œê¸€/ê³µë°± ë“±ë„ ì•ˆì „í•˜ê²Œ ì“°ê³  ì‹¶ë‹¤ë©´ í•„ìš”ì‹œ ë” ì¤„ì¼ ìˆ˜ ìˆìŒ
    - ë„ˆë¬´ ê¸¸ì–´ì§€ì§€ ì•Šë„ë¡ 50ì ì •ë„ë¡œ ì˜ë¼ì¤Œ
    """
    if not tag:
        return "tag"

    # ì¼ë‹¨ ë¬¸ìì—´ë¡œ ìºìŠ¤íŒ…
    s = str(tag)

    # ìœˆë„ìš°ì—ì„œ ì•ˆ ë˜ëŠ” ë¬¸ìë“¤ ì „ë¶€ '_'ë¡œ ì¹˜í™˜
    s = re.sub(r'[\\/:*?"<>|]', "_", s)

    # ì•ë’¤ ê³µë°±/ë§ˆì¹¨í‘œ ì œê±° (ìœˆë„ìš° íŒŒì¼ëª… ëì— . / ê³µë°± ì•ˆ ë¨)
    s = s.strip().rstrip(". ")

    # ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ ì‚¬ìš©
    if len(s) > 50:
        s = s[:50]

    # ì™„ì „ ë¹ˆ ë¬¸ìì—´ì´ ë˜ë©´ fallback
    if not s:
        s = "tag"

    return s

def paint_color_swatches(xlsx_path: Path, swatch_col_name: str, header_row: int = 1):
    wb = load_workbook(xlsx_path)
    ws = wb.active
    col_idx = None
    for c in range(1, ws.max_column + 1):
        if (ws.cell(row=header_row, column=c).value or "").strip() == swatch_col_name:
            col_idx = c
            break
    if col_idx is None:
        wb.close()
        return

    for r in range(header_row + 1, ws.max_row + 1):
        hex_val = ws.cell(row=r, column=col_idx).value
        if isinstance(hex_val, str) and hex_val.strip():
            argb = hex_to_argb(hex_val)
            ws.cell(row=r, column=col_idx).fill = PatternFill(
                fill_type="solid", start_color=argb, end_color=argb
            )

    wb.save(xlsx_path)
    wb.close()


# ============== ìœ í‹¸ ==============
def srgb_int_to_rgb8(srgb_int: int) -> Tuple[int, int, int]:
    r, g, b = fitz.sRGB_to_rgb(srgb_int)
    return int(r), int(g), int(b)


def rgb8_to_hex(rgb: Tuple[int, int, int]) -> str:
    r, g, b = rgb
    return f"#{r:02X}{g:02X}{b:02X}"


def bbox_center(b: Tuple[float, float, float, float]) -> Tuple[float, float]:
    x0, y0, x1, y1 = b
    return (x0 + x1) / 2.0, (y0 + y1) / 2.0


def bbox_union(a: Tuple[float, float, float, float],
               b: Tuple[float, float, float, float]) -> Tuple[float, float, float, float]:
    ax0, ay0, ax1, ay1 = a
    bx0, by0, bx1, by1 = b
    return min(ax0, bx0), min(ay0, by0), max(ax1, bx1), max(ay1, by1)


# ============== íƒœê·¸ ì •ê·œì‹ ==============
# PID NO (ì˜ˆ: 216112C-11-PID-0021-0104)
PID_TAG_RE = re.compile(
    r'^[0-9A-Z]+-\d+-PID-\d{4}-\d{4}$',
    re.IGNORECASE,
)
# ë¼ì¸ë„˜ë²„ (ì¸ì¹˜, ì‚¬ì´ì¦ˆ í¬í•¨)
LINE_TAG_RE = re.compile(
    r'^\d{1,3}-.*"-[A-Z]{1,3}-\d{3,6}-[A-Z0-9]{3,}-[A-Z]$',
    re.IGNORECASE,
)

# ì¥ë¹„ íƒœê·¸
EQUIP_TAG_RE = re.compile(
    r'^\d{1,3}-[A-Z]{1,4}-\d{2,5}(?:-[A-Z](?:/[A-Z])?)?$',
    re.IGNORECASE,
)

TAG_PATTERNS = {
    "line_no": re.compile(r"\b[0-9]{2,4}-[A-Z0-9]{2,}-[0-9A-Z\-]{4,}\b"),
    "valve": re.compile(r"\b(?:[A-Z]{1,3})-?\d{3,5}[A-Z]?\b"),
    "instr": re.compile(r"\b[A-Z]{1,3}-?\d{1,5}[A-Z]?\b"),
    "special": re.compile(r"\b(?:SPV|EXJ)\s?-?\s?[0-9A-Z\-]{2,}\b"),
}


def classify_tag(text: str) -> str:
    raw = (text or "").strip()
    if not raw:
        return "text"

    upper = raw.upper()

    # 1) equipment ë¨¼ì € ë§¤ì¹­
    # ì˜ˆ) 11-P-621-A/B, 11-C-620, 11-PM-621-A/B
    if EQUIP_TAG_RE.fullmatch(upper):
        return "equipment"

    # 2) line (ì¸ì¹˜, ì‚¬ì´ì¦ˆ í¬í•¨ ë¼ì¸ë„˜ë²„)
    # ì˜ˆ) 11-6"-MW-10401-F242A-H, 11-1 1/2"-PC-13105-F400A-H
    if LINE_TAG_RE.fullmatch(upper) or TAG_PATTERNS["line_no"].search(upper):
        return "line"

    # 3) ë‚˜ë¨¸ì§€ëŠ” ê¸°ì¡´ ë¡œì§ ìœ ì§€
    if "IF" in upper:
        return "interface"
    if TAG_PATTERNS["special"].search(upper):
        return "special"
    if TAG_PATTERNS["valve"].search(upper):
        return "valve"
    if TAG_PATTERNS["instr"].search(upper):
        return "instrument"
    return "text"


# ============== ë°ì´í„° êµ¬ì¡° ==============
@dataclass
class SpanRec:
    page: int
    text: str
    bbox: Tuple[float, float, float, float]
    rgb: Tuple[int, int, int]
    color_hex: str
    type: str
    pdf_name: str = ""


@dataclass
class ComposedTag:
    page: int
    code: str
    number: str
    composed: str
    code_bbox: Tuple[float, float, float, float]
    number_bbox: Optional[Tuple[float, float, float, float]]
    union_bbox: Tuple[float, float, float, float]
    code_hex: str
    num_hex: Optional[str]
    dy: Optional[float]


# ============== ì£¼ì„(ë§ˆí¬ì—…) í´ë¦¬ê³¤ ìˆ˜ì§‘ ==============
def collect_markup_polygons(page: fitz.Page) -> List[Polygon]:
    polys: List[Polygon] = []
    annots = page.annots()
    if not annots:
        logger.debug("  ì£¼ì„ ì—†ìŒ")
        return polys

    for annot in annots:
        polygon_coords = None

        # Polygon / Highlight íƒ€ì… (vertices ì¡´ì¬)
        if hasattr(annot, "vertices") and annot.vertices:
            raw_vertices = annot.vertices
            coords: List[Tuple[float, float]] = []
            for v in raw_vertices:
                # (x, y) íŠœí”Œ í˜¹ì€ Point ëª¨ë‘ ì§€ì›
                if hasattr(v, "x") and hasattr(v, "y"):
                    coords.append((float(v.x), float(v.y)))
                elif isinstance(v, (tuple, list)) and len(v) >= 2:
                    coords.append((float(v[0]), float(v[1])))
            if len(coords) >= 3:
                poly = Polygon(coords)
                polys.append(poly)
                logger.info(f"  Found {annot.type[1]} markup: {len(coords)} vertices")

        # Square íƒ€ì…(rect ì‚¬ìš©)
        elif annot.type[0] == 4:  # Square
            rect = annot.rect
            coords = [
                (rect.x0, rect.y0),
                (rect.x1, rect.y0),
                (rect.x1, rect.y1),
                (rect.x0, rect.y1),
            ]
            poly = Polygon(coords)
            polys.append(poly)
            logger.info(f"  Found Square markup: {rect}")

    logger.info(f"  Total markup regions: {len(polys)}")
    return polys


# ============== ë§ˆí¬ì—… ì œì™¸ í…ìŠ¤íŠ¸ span ìˆ˜ì§‘ ==============
def collect_spans_excluding_markup(
    page: fitz.Page,
    markup_polygons: List[Polygon],
    pdf_name: str = ""
) -> List[SpanRec]:
    """
    - í˜ì´ì§€ì—ì„œ ëª¨ë“  í…ìŠ¤íŠ¸ span ìˆ˜ì§‘
    - span ì¤‘ì‹¬ì ì´ markup í´ë¦¬ê³¤ ì•ˆì— ìˆìœ¼ë©´ ì œì™¸
    - ìƒ‰ìƒì€ ëª¨ë‘ í—ˆìš© (ê²€ì •/íšŒìƒ‰ í¬í•¨)
    """
    spans: List[SpanRec] = []
    d = page.get_text("dict")
    for blk in d.get("blocks", []):
        for line in blk.get("lines", []):
            for s in line.get("spans", []):
                text = (s.get("text") or "").strip()
                if not text:
                    continue

                x0, y0, x1, y1 = s["bbox"]
                cx, cy = bbox_center((x0, y0, x1, y1))
                pt = Point(cx, cy)

                in_markup = False
                for poly in markup_polygons:
                    if poly.contains(pt):
                        in_markup = True
                        break
                if in_markup:
                    # ë§ˆí¬ì—… ì˜ì—­ ë‚´ë¶€ í…ìŠ¤íŠ¸ëŠ” ì œì™¸
                    continue

                srgb_int = s.get("color")
                if srgb_int is not None:
                    rgb = srgb_int_to_rgb8(srgb_int)
                    color_hex = rgb8_to_hex(rgb)
                else:
                    rgb = (0, 0, 0)
                    color_hex = "#000000"

                spans.append(
                    SpanRec(
                        page=page.number + 1,
                        text=text,
                        bbox=(float(x0), float(y0), float(x1), float(y1)),
                        rgb=rgb,
                        color_hex=color_hex,
                        type=classify_tag(text),
                        pdf_name=pdf_name,
                    )
                )

    logger.info(f"  spans collected (excluding markup): {len(spans)}")
    return spans


# ============== ë‘ ì¤„ ë¼ì¸ë„˜ë²„ ë³‘í•© íŒŒë¼ë¯¸í„° ==============
LINE_PREFIX_RE = re.compile(
    r"^[0-9]{2,4}-[A-Z0-9]{2,}-[A-Z0-9\-]*-$", re.IGNORECASE
)
LINE_MERGE_DY_MAX = 25.0
LINE_MERGE_X_CENTER_TOL = 15.0


def merge_multiline_line_numbers(spans: List[SpanRec]) -> List[SpanRec]:
    """ë‘ ì¤„ë¡œ ë‚˜ë‰œ ë¼ì¸ë„˜ë²„ ë³‘í•© (ê¸°ì¡´ ë¡œì§ ìœ ì§€)"""
    if not spans:
        return spans

    groups: Dict[Tuple[int, str], List[SpanRec]] = {}
    for s in spans:
        groups.setdefault((s.page, s.color_hex), []).append(s)

    merged_all: List[SpanRec] = []
    for (_, _), S in groups.items():
        S_sorted = sorted(S, key=lambda s: (s.bbox[1], s.bbox[0]))
        used = set()
        n = len(S_sorted)

        for i, s in enumerate(S_sorted):
            if i in used:
                continue

            text_top = (s.text or "").strip()
            upper_top = text_top.upper()

            if text_top.endswith("-") and LINE_PREFIX_RE.match(upper_top):
                scx, scy = bbox_center(s.bbox)
                merged_flag = False

                for j in range(i + 1, n):
                    if j in used:
                        continue
                    t = S_sorted[j]

                    dy = t.bbox[1] - s.bbox[3]
                    if dy < 0:
                        continue
                    if dy > LINE_MERGE_DY_MAX:
                        break

                    tcx, tcy = bbox_center(t.bbox)
                    if abs(tcx - scx) > LINE_MERGE_X_CENTER_TOL:
                        continue

                    text_bottom = (t.text or "").strip()
                    combined = text_top + text_bottom

                    if TAG_PATTERNS["line_no"].search(combined):
                        new_bbox = bbox_union(s.bbox, t.bbox)
                        merged_span = SpanRec(
                            page=s.page,
                            text=combined,
                            bbox=new_bbox,
                            rgb=s.rgb,
                            color_hex=s.color_hex,
                            type=classify_tag(combined),
                            pdf_name=s.pdf_name,
                        )
                        merged_all.append(merged_span)
                        used.add(i)
                        used.add(j)
                        merged_flag = True
                        break

                if not merged_flag:
                    merged_all.append(s)
            else:
                merged_all.append(s)

    return merged_all


# ============== ì½”ë“œ+ìˆ«ì ë§¤ì¹­ íŒŒë¼ë¯¸í„° ==============
DX_TOL_CENTER = 11.0
DY_TOL_CENTER = 18.0

TARGET_DX = -39.1
TARGET_DY = 1.3
DX_TOL = 32.0
DY_TOL = 22.0
EXPANSIONS = [1.0, 1.5]

CODE_ONLY_RE = re.compile(r"^[A-Z]{1,4}$")
NUMBER_ONLY_RE = re.compile(r"^\d{2,5}\s*[A-Z]{0,2}$")
LETTER_ONLY_RE = re.compile(r"^[A-Z]{1,3}$")

SUFFIX_LINE_TOL = 4.0
SUFFIX_GAP_MAX  = 60.0

EXCLUDE_CODES = {"O", "L", "LL"}


def _stitch_suffix(number_span: SpanRec,
                   spans_on_page: List[SpanRec]) -> Tuple[str, Tuple[float, float, float, float]]:
    base_text = re.sub(r"\s+", "", number_span.text)
    x0, y0, x1, y1 = number_span.bbox
    ncx, ncy = bbox_center(number_span.bbox)

    suffixes: List[SpanRec] = []
    for sp in spans_on_page:
        if sp is number_span:
            continue
        if not LETTER_ONLY_RE.match(sp.text):
            continue
        scx, scy = bbox_center(sp.bbox)
        if abs(scy - ncy) > SUFFIX_LINE_TOL: continue
        if (sp.bbox[0] - x1) >= -2 and (sp.bbox[0] - x1) <= SUFFIX_GAP_MAX:
            suffixes.append(sp)

    suffixes.sort(key=lambda s: s.bbox[0])
    stitched = base_text
    stitched_bbox = (x0, y0, x1, y1)
    appended = 0
    for sp in suffixes:
        if appended >= 2:
            break
        stitched += sp.text
        sx0, sy0, sx1, sy1 = sp.bbox
        stitched_bbox = (
            min(stitched_bbox[0], sx0),
            min(stitched_bbox[1], sy0),
            max(stitched_bbox[2], sx1),
            max(stitched_bbox[3], sy1),
        )
        appended += 1

    return stitched, stitched_bbox


def _pick_by_window(numbers: List[SpanRec],
                    rx0: float, ry0: float, rx1: float, ry1: float,
                    tx: float, ty: float, cy1: float) -> Optional[Tuple[float, float, SpanRec]]:
    cand = []
    for n in numbers:
        ncx, ncy = bbox_center(n.bbox)
        if rx0 <= ncx <= rx1 and ry0 <= ncy <= ry1:
            ny0 = n.bbox[1]
            dist2 = (ncx - tx) ** 2 + (ncy - ty) ** 2
            dy = ny0 - cy1
            cand.append((dist2, dy, n))
    if not cand:
        return None
    cand.sort(key=lambda x: x[0])
    return cand[0]


def compose_vertical_pairs_simple(spans: List[SpanRec]) -> List[ComposedTag]:
    comps: List[ComposedTag] = []
    spans_by_page: Dict[int, List[SpanRec]] = {}
    for sp in spans:
        spans_by_page.setdefault(sp.page, []).append(sp)

    for page, S in spans_by_page.items():
        codes = [
            s for s in S
            if CODE_ONLY_RE.match(s.text) and s.text not in EXCLUDE_CODES
        ]
        numbers = [s for s in S if NUMBER_ONLY_RE.match(s.text)]

        for c in codes:
            cx0, cy0, cx1, cy1 = c.bbox
            ccx, _ = bbox_center(c.bbox)

            chosen = None
            tx = ccx
            ty = cy1 + 0.0
            win = (tx - DX_TOL_CENTER, ty - DY_TOL_CENTER,
                   tx + DX_TOL_CENTER, ty + DY_TOL_CENTER)
            chosen = _pick_by_window(numbers, *win, tx=tx, ty=ty, cy1=cy1)

            if not chosen:
                tx = ccx + TARGET_DX
                ty = cy1 + TARGET_DY
                for scale in EXPANSIONS:
                    win = (tx - DX_TOL * scale, ty - DY_TOL * scale,
                           tx + DX_TOL * scale, ty + DY_TOL * scale)
                    chosen = _pick_by_window(numbers, *win, tx=tx, ty=ty, cy1=cy1)
                    if chosen:
                        break

            if chosen:
                _, dy, n = chosen
                stitched_text, stitched_bbox = _stitch_suffix(n, S)
                comps.append(
                    ComposedTag(
                        page=page,
                        code=c.text,
                        number=stitched_text,
                        composed=f"{c.text}-{stitched_text}",
                        code_bbox=c.bbox,
                        number_bbox=stitched_bbox,
                        union_bbox=bbox_union(c.bbox, stitched_bbox),
                        code_hex=c.color_hex,
                        num_hex=n.color_hex,
                        dy=dy,
                    )
                )
            else:
                comps.append(
                    ComposedTag(
                        page=page,
                        code=c.text,
                        number="",
                        composed=c.text,
                        code_bbox=c.bbox,
                        number_bbox=None,
                        union_bbox=c.bbox,
                        code_hex=c.color_hex,
                        num_hex=None,
                        dy=None,
                    )
                )

    return comps


# ============== PDF ì²˜ë¦¬ (ë§ˆí¬ì—… ì œì™¸ + ì •ì œ) ==============
def process_pdf(pdf_path: Path):
    logger.info(f"PDF ì²˜ë¦¬ ì‹œì‘: {pdf_path.name}")
    doc = fitz.open(pdf_path.as_posix())
    all_spans: List[SpanRec] = []
    all_comp: List[ComposedTag] = []

    for i, page in enumerate(doc, start=1):
        t0 = time.time()
        try:
            logger.info(f"\n=== Processing Page {i}/{doc.page_count} ===")
            markup_polygons = collect_markup_polygons(page)
            spans = collect_spans_excluding_markup(page, markup_polygons, pdf_name=pdf_path.name)
            #spans = merge_multiline_line_numbers(spans)
            comps = compose_vertical_pairs_simple(spans)

            all_spans.extend(spans)
            all_comp.extend(comps)

            logger.info(
                f"  page {i}/{doc.page_count}: spans={len(spans)} "
                f"composed={len(comps)} ({time.time() - t0:.2f}s)"
            )
        except Exception as e:
            logger.exception(f"  page {i} ì˜¤ë¥˜: {e} -> ê±´ë„ˆëœ€")
            continue

    doc.close()
    logger.info(
        f"PDF ì™„ë£Œ: {pdf_path.name} "
        f"(spans={len(all_spans)}, composed={len(all_comp)})"
    )
    return all_spans, all_comp


def to_dataframe(spans: List[SpanRec], comps: List[ComposedTag]):

    df_spans = pd.DataFrame([{
        "page": s.page,
        "tag": s.text,
        "type": s.type,
        "x1": s.bbox[0], "y1": s.bbox[1],
        "x2": s.bbox[2], "y2": s.bbox[3],
        "rgb": s.rgb,
        "hex": s.color_hex,
        "hex_swatch": s.color_hex,
        "pdf_name": s.pdf_name
    } for s in spans])

    df_comp = pd.DataFrame([{
        "page": c.page,
        "code": c.code,
        "number": c.number,
        "composed": c.composed,

        "code_x1": c.code_bbox[0], "code_y1": c.code_bbox[1],
        "code_x2": c.code_bbox[2], "code_y2": c.code_bbox[3],

        "num_x1": c.number_bbox[0] if c.number_bbox else None,
        "num_y1": c.number_bbox[1] if c.number_bbox else None,
        "num_x2": c.number_bbox[2] if c.number_bbox else None,
        "num_y2": c.number_bbox[3] if c.number_bbox else None,

        "u_x1": c.union_bbox[0], "u_y1": c.union_bbox[1],
        "u_x2": c.union_bbox[2], "u_y2": c.union_bbox[3],

        "code_hex": c.code_hex,
        "num_hex": c.num_hex,

        "code_hex_swatch": c.code_hex,
        "num_hex_swatch": c.num_hex,

        "dy": c.dy
    } for c in comps])

    if not df_spans.empty and not df_comp.empty:
        df_comp_nonempty = df_comp[df_comp["number"].astype(str) != ""]
        used_indices = set()

        def _center_dist2(b1, b2):
            c1x, c1y = bbox_center(b1)
            c2x, c2y = bbox_center(b2)
            return (c1x - c2x) ** 2 + (c1y - c2y) ** 2

        for _, row in df_comp_nonempty.iterrows():
            page = row["page"]
            code = row["code"]
            composed = row["composed"]
            code_hex = row["code_hex"]

            # í›„ë³´: ê°™ì€ page + ê°™ì€ code í…ìŠ¤íŠ¸ + ê°™ì€ ìƒ‰(hex)
            candidates = df_spans[
                (df_spans["page"] == page) &
                (df_spans["tag"] == code) &
                (df_spans["hex"] == code_hex)
            ]

            if candidates.empty:
                continue

            # ì´ë¯¸ ë‹¤ë¥¸ composedê°€ ì‚¬ìš©í•œ span ì œì™¸
            candidates = candidates[~candidates.index.isin(used_indices)]
            if candidates.empty:
                continue

            # code_bboxì™€ ê°€ì¥ ê°€ê¹Œìš´ span í•˜ë‚˜ ì„ íƒ
            code_bbox = (row["code_x1"], row["code_y1"],
                         row["code_x2"], row["code_y2"])

            dist2 = candidates.apply(
                lambda r: _center_dist2(
                    (r["x1"], r["y1"], r["x2"], r["y2"]),
                    code_bbox
                ),
                axis=1
            )

            best_idx = dist2.idxmin()
            used_indices.add(best_idx)

            # í•´ë‹¹ span 1ê°œë§Œ composedë¡œ ì¹˜í™˜
            df_spans.loc[best_idx, "tag"] = composed
            df_spans.loc[best_idx, "type"] = "instrument"
            df_spans.loc[best_idx, ["x1", "y1", "x2", "y2"]] = [
                row["u_x1"], row["u_y1"], row["u_x2"], row["u_y2"]
            ]

    if not df_spans.empty:
        df_spans["tag"] = df_spans["tag"].astype(str)

        # (1) ì œì™¸ ì½”ë“œ(O, L, LL)
        mask_exclude_codes = df_spans["tag"].isin(EXCLUDE_CODES)

        # (2) ìˆ«ìë§Œ ìˆëŠ” ê°’
        mask_digits_only = df_spans["tag"].str.fullmatch(r"\d+")

        # (3) ì•ŒíŒŒ+ìˆ«ìë§Œ ë¶™ì€ ë‹¨ì–´ (7302A, A4500, N05 ë“±)
        upper_tags = df_spans["tag"].str.upper()
        mask_alnum_word = upper_tags.str.fullmatch(r"(?=.*[A-Z])(?=.*\d)[A-Z0-9]+")

        df_spans = df_spans[~(mask_exclude_codes | mask_digits_only | mask_alnum_word)].copy()

        # ì •ë ¬ í›„ (tag, page, hex) ë‹¨ìœ„ ì¤‘ë³µ ì œê±°
        df_spans = (
            df_spans
            .sort_values(["tag", "page", "hex", "x1", "y1"])
            .drop_duplicates(["tag", "page", "hex"], keep="first")
        )

    return df_spans, df_comp



# ============== YOLO ëª¨ë¸ ë¡œë“œ ==============
def load_yolo_model(model_path: Path) -> Optional["YOLO"]:
    if not YOLO_AVAILABLE:
        logger.warning("YOLO ë¯¸ì‚¬ìš© - ultralytics ë¯¸ì„¤ì¹˜")
        return None

    if not model_path.exists():
        logger.warning(f"YOLO ëª¨ë¸ ì—†ìŒ: {model_path} - ìë™ ë¶„ë¥˜ ê±´ë„ˆëœ€")
        return None

    try:
        model = YOLO(model_path.as_posix())
        logger.info(f"âœ… YOLO ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
        return model
    except Exception as e:
        logger.error(f"YOLO ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None


# ============== PDF ì¢Œí‘œë¡œ ì´ë¯¸ì§€ Crop ==============
def crop_bbox_from_pdf(
    pdf_path: Path,
    page_num: int,
    bbox: Tuple[float, float, float, float],
    margin: int = CROP_MARGIN,
) -> Optional[Image.Image]:
    """
    PDFì—ì„œ íŠ¹ì • bbox ì˜ì—­ì„ ì˜ë¼ 800x800 íŒ¨ë”©ëœ ì´ë¯¸ì§€ë¥¼ ë°˜í™˜
    """
    try:
        doc = fitz.open(pdf_path.as_posix())
        page = doc[page_num - 1]

        x0, y0, x1, y1 = bbox

        x0 = max(0, x0 - margin)
        y0 = max(0, y0 - margin)
        x1 = min(page.rect.width, x1 + margin)
        y1 = min(page.rect.height, y1 + margin)

        clip_rect = fitz.Rect(x0, y0, x1, y1)
        pix = page.get_pixmap(clip=clip_rect, matrix=fitz.Matrix(2.0, 2.0))

        import cv2
        import numpy as np

        img_data = pix.tobytes("png")
        img_pil = Image.open(io.BytesIO(img_data))
        img_array = np.array(img_pil)

        # RGB â†’ BGR
        if len(img_array.shape) == 3 and img_array.shape[2] == 3:
            img_cv = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
        else:
            img_cv = img_array

        tile_size = 800
        h, w = img_cv.shape[:2]

        # ì‘ì€ ê²½ìš° íŒ¨ë”©
        if h < tile_size or w < tile_size:
            img_cv = cv2.copyMakeBorder(
                img_cv,
                0,
                max(0, tile_size - h),
                0,
                max(0, tile_size - w),
                cv2.BORDER_CONSTANT,
                value=[255, 255, 255],
            )
        # í° ê²½ìš° ì¤‘ì•™ í¬ë¡­ (+ í•„ìš”ì‹œ ì¬íŒ¨ë”©)
        elif h > tile_size or w > tile_size:
            center_y, center_x = h // 2, w // 2
            y0c = max(0, center_y - tile_size // 2)
            x0c = max(0, center_x - tile_size // 2)
            y1c = min(h, y0c + tile_size)
            x1c = min(w, x0c + tile_size)
            img_cv = img_cv[y0c:y1c, x0c:x1c]

            h_new, w_new = img_cv.shape[:2]
            if h_new < tile_size or w_new < tile_size:
                img_cv = cv2.copyMakeBorder(
                    img_cv,
                    0,
                    max(0, tile_size - h_new),
                    0,
                    max(0, tile_size - w_new),
                    cv2.BORDER_CONSTANT,
                    value=[255, 255, 255],
                )

        img_rgb = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)
        img_pil_final = Image.fromarray(img_rgb)

        logger.debug(f"    Crop ì´ë¯¸ì§€ í¬ê¸°: {img_pil_final.size}")

        doc.close()
        return img_pil_final

    except Exception as e:
        logger.error(f"ì´ë¯¸ì§€ crop ì‹¤íŒ¨ (page {page_num}, bbox {bbox}): {e}")
        return None


# ============== YOLOë¡œ special_item íŒì • ==============
def classify_with_yolo(
    model: "YOLO",
    img: Image.Image,
    confidence: float = YOLO_CONFIDENCE,
) -> bool:
    try:
        results = model(img, conf=confidence, imgsz=800, verbose=False)

        if len(results) == 0 or len(results[0].boxes) == 0:
            return False

        for box in results[0].boxes:
            class_id = int(box.cls[0])
            if class_id == 0:  # special_item
                return True

        return False

    except Exception as e:
        logger.error(f"YOLO ì¶”ë¡  ì‹¤íŒ¨: {e}")
        return False


# ============== instrument â†’ special_item ì¬ë¶„ë¥˜ ==============
def reclassify_instruments_with_yolo(
    df_spans: pd.DataFrame,
    pdf_dir: Path,
    model: Optional["YOLO"],
) -> pd.DataFrame:
    if model is None:
        logger.info("YOLO ëª¨ë¸ ì—†ìŒ - ì¬ë¶„ë¥˜ ìŠ¤í‚µ")
        return df_spans

    if df_spans.empty:
        return df_spans

    instruments = df_spans[df_spans["type"] == "instrument"].copy()
    if instruments.empty:
        logger.info("instrument íƒ€ì… ì—†ìŒ - ì¬ë¶„ë¥˜ ìŠ¤í‚µ")
        return df_spans

    logger.info(f"ğŸ” YOLO ì¬ë¶„ë¥˜ ì‹œì‘: {len(instruments)}ê°œ instrument ê²€ì‚¬")

    reclassified_indices = []
    processed = 0

    preprocessed_dir = CROP_IMG_DIR / "preprocessed_800x800"
    preprocessed_dir.mkdir(exist_ok=True)

    import cv2
    import numpy as np

    for idx, row in instruments.iterrows():
        pdf_name = row["pdf_name"]
        pdf_path = pdf_dir / pdf_name

        if not pdf_path.exists():
            logger.warning(f"PDF ì—†ìŒ: {pdf_path}")
            continue

        page_num = int(row["page"])
        bbox = (row["x1"], row["y1"], row["x2"], row["y2"])
        tag = row["tag"]

        img = crop_bbox_from_pdf(pdf_path, page_num, bbox, margin=CROP_MARGIN)
        if img is None:
            continue

        # â˜… íŒŒì¼ëª… ì•ˆì „í•˜ê²Œ ì„¸íƒ
        safe_tag = make_safe_tag_for_filename(tag)
        img_filename = f"{Path(pdf_name).stem}_p{page_num}_{safe_tag}_{idx}.jpg"

        if SAVE_CROPPED_IMAGES:
            import cv2
            import numpy as np

            # ì›ë³¸ crop ì €ì¥
            img.save(CROP_IMG_DIR / img_filename, "JPEG", quality=95)

            # ì „ì²˜ë¦¬ í›„ 800x800 ì €ì¥
            img_array = np.array(img)
            if len(img_array.shape) == 3:
                img_cv = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
            else:
                img_cv = img_array

            target_size = 800
            h, w = img_cv.shape[:2]
            scale = min(target_size / w, target_size / h)
            new_w, new_h = int(w * scale), int(h * scale)
            resized = cv2.resize(img_cv, (new_w, new_h))

            padded = np.full((target_size, target_size, 3), 255, dtype=np.uint8)
            y_offset = (target_size - new_h) // 2
            x_offset = (target_size - new_w) // 2
            padded[y_offset:y_offset + new_h, x_offset:x_offset + new_w] = resized

            cv2.imwrite(str(preprocessed_dir / img_filename), padded)

        # YOLO íŒì •
        is_special = classify_with_yolo(model, img, confidence=YOLO_CONFIDENCE)
        if is_special:
            reclassified_indices.append(idx)
            logger.debug(f"  âœ… special_item ë°œê²¬: {tag} (page {page_num})")

        processed += 1
        if processed % 50 == 0:
            logger.info(
                f"  ì§„í–‰: {processed}/{len(instruments)} "
                f"({len(reclassified_indices)} special_item)"
            )

    if reclassified_indices:
        df_spans.loc[reclassified_indices, "type"] = "special_item"
        logger.info(
            f"âœ¨ ì¬ë¶„ë¥˜ ì™„ë£Œ: {len(reclassified_indices)}ê°œ "
            f"instrument â†’ special_item"
        )
    else:
        logger.info("ì¬ë¶„ë¥˜ ê²°ê³¼: special_item ì—†ìŒ")

    if SAVE_CROPPED_IMAGES:
        saved_count = len(list(CROP_IMG_DIR.glob("*.jpg")))
        logger.info(
            f"ğŸ’¾ Cropped ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {saved_count}ê°œ â†’ {CROP_IMG_DIR}"
        )

    return df_spans

def attach_pid_no_by_page(df_spans: pd.DataFrame) -> pd.DataFrame:
    """
    ê° pageë§ˆë‹¤ PID_TAG_REì— ë§¤ì¹­ë˜ëŠ” íƒœê·¸ë¥¼ ì°¾ì•„ì„œ
    'PID NO' ì»¬ëŸ¼ìœ¼ë¡œ ë¶™ì—¬ì¤€ë‹¤.
    - í˜ì´ì§€ë‹¹ 1ê°œë¼ê³  ê°€ì •
    - 0ê°œë©´ None
    - 2ê°œ ì´ìƒì´ë©´ ì²« ë²ˆì§¸ë§Œ ì“°ê³  warning
    """
    if df_spans.empty:
        df_spans["PID NO"] = None
        return df_spans

    pid_by_page = {}

    for page, grp in df_spans.groupby("page"):
        tags = grp["tag"].astype(str)

        candidates = tags[tags.str.match(PID_TAG_RE, na=False)]

        if len(candidates) == 1:
            pid_val = candidates.iloc[0]
        elif len(candidates) > 1:
            pid_val = candidates.iloc[0]
            logger.warning(
                f"page {page}: PID í›„ë³´ê°€ {len(candidates)}ê°œ â†’ ì²« ë²ˆì§¸ë§Œ ì‚¬ìš©: {pid_val}"
            )
        else:
            pid_val = None
            logger.warning(f"page {page}: PID íŒ¨í„´ ë§¤ì¹­ ì—†ìŒ")

        pid_by_page[page] = pid_val

    df_spans["PID NO"] = df_spans["page"].map(pid_by_page)
    return df_spans

# ============== ë©”ì¸ ==============
def main():
    logger.add(OUT_DIR / "pdf_color_extract.log", rotation="500 KB")

    pdf_list = sorted(DATA_PDF_DIR.glob("*.pdf"))
    if not pdf_list:
        logger.error(f"PDFê°€ ì—†ìŠµë‹ˆë‹¤: {DATA_PDF_DIR.resolve()}")
        return

    # 1) PDFë“¤ ì²˜ë¦¬ â†’ SpanRec / ComposedTag ìˆ˜ì§‘
    Gs: List[SpanRec] = []
    Gc: List[ComposedTag] = []
    for pdf in pdf_list:
        try:
            s, c = process_pdf(pdf)
            Gs.extend(s)
            Gc.extend(c)
        except Exception as e:
            logger.exception(f"{pdf.name} ì²˜ë¦¬ ì˜¤ë¥˜: {e} -> ê±´ë„ˆëœ€")
            continue

    # 2) DataFrame ë³€í™˜ + composed ë°˜ì˜ + ì •ì œ
    df_spans, df_comp = to_dataframe(Gs, Gc)

    # 3) YOLOë¡œ instrument â†’ special_item ì¬ë¶„ë¥˜

    model = load_yolo_model(YOLO_MODEL_PATH)
    df_spans = reclassify_instruments_with_yolo(df_spans, DATA_PDF_DIR, model)
    df_spans = attach_pid_no_by_page(df_spans)
    df_spans = df_spans[df_spans["type"] != "text"].copy()

    # 4) ê¸°ì¡´ ê²°ê³¼ ì €ì¥ (colored_tags / composed_tags)
    xlsx_spans = OUT_DIR / "colored_tags_without_pkg.xlsx"
    xlsx_comp = OUT_DIR / "colored_tags_without_pkg_com.xlsx"

    df_spans.to_excel(xlsx_spans, index=False)
    df_comp.to_excel(xlsx_comp, index=False)

    # ìƒ‰ìƒ ìŠ¤ì™€ì¹˜ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    for path, col in [
        (xlsx_spans, "hex_swatch"),
        (xlsx_comp, "code_hex_swatch"),
        (xlsx_comp, "num_hex_swatch"),
    ]:
        try:
            paint_color_swatches(path, swatch_col_name=col)
        except Exception as e:
            logger.warning(f"{path.name} ìŠ¤ì™€ì¹˜ ê²½ê³ : {e}")

    logger.info(f"SAVED â†’ {xlsx_spans},  {xlsx_comp}")

    # 5) âœ… ìµœì¢… ê²°ê³¼: page, text, type, x0, y0, x1, y1 í˜•ì‹ìœ¼ë¡œ ë³„ë„ ì €ì¥
    if not df_spans.empty:
        df_final = (
            df_spans.rename(
                columns={
                    "tag": "text",
                    "x1": "x0",
                    "y1": "y0",
                    "x2": "x1",
                    "y2": "y1",
                }
            )[["page", "PID NO", "text", "type", "x0", "y0", "x1", "y1"]]
            .reset_index(drop=True)
        )
        df_final = df_final[df_final["type"] != "text"].reset_index(drop=True)

        final_xlsx = OUT_DIR / "final_tags.xlsx"
        df_final.to_excel(final_xlsx, index=False)

        logger.info(
            f"âœ… ìµœì¢… ê²°ê³¼ ì €ì¥ â†’ {final_xlsx} "
            f"(cols: page, PID NO, text, type, x0, y0, x1, y1)"
        )


if __name__ == "__main__":
    main()
